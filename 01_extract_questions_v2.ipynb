{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2dabd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rono\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Baringo_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Bomet_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Bungoma_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Busia_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Elgeyo_Marakwet_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Embu_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Garissa_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Homa_Bay_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Isiolo_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kajiado_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kakamega_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kericho_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kiambu_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kilifi_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kirinyaga_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kisii_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kisumu_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kitui_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Kwale_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Laikipia_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Machakos_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Migori_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Murang’a_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Nakuru_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Nandi_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Narok_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Nyamira_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Nyandarua_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Nyeri_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Siaya_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Taita_Taveta_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Tana_River_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Tharaka_Nithi_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Trans-Nzoia_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Turkana_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Uasin_Gishu_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: Vihiga_gendered_enterprise_selection_interview_guide.docx\n",
      "Processing: West_Pokot_gendered_enterprise_selection_interview_guide.docx\n",
      "✅ Done. Extracted Excel files are saved in: d:\\AAAA_Data\\GENDER\\extracted_excel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from rapidfuzz import fuzz\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# ==========================\n",
    "# 1️⃣ AUTO-DETECT WORKING DIRECTORY\n",
    "# ==========================\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "INPUT_DIR = os.path.join(BASE_DIR, \"Questionnaires\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"extracted_excel\")\n",
    "LOOKUP_JSON = os.path.join(BASE_DIR, \"lookup.json\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# 2️⃣ LOAD QUESTION MAPPING\n",
    "# ==========================\n",
    "with open(LOOKUP_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    QUESTION_MAPPING = json.load(f)\n",
    "\n",
    "ALL_QUESTION_VARIANTS = set()\n",
    "ALL_THEMES = set(QUESTION_MAPPING.keys())\n",
    "\n",
    "for theme, question_dict in QUESTION_MAPPING.items():\n",
    "    for variants in question_dict.values():\n",
    "        for variant in variants:\n",
    "            ALL_QUESTION_VARIANTS.add(variant.strip().lower())\n",
    "\n",
    "# ==========================\n",
    "# 3️⃣ CLEAN TEXT FUNCTION\n",
    "# ==========================\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    return re.sub(r'\\s+', ' ', str(text).strip())\n",
    "\n",
    "# ==========================\n",
    "# 4️⃣ CHECK IF LINE IS QUESTION OR THEME\n",
    "# ==========================\n",
    "def is_question_or_theme(line, threshold=90):\n",
    "    line = line.strip().lower()\n",
    "    if not line:\n",
    "        return False\n",
    "\n",
    "    for q in ALL_QUESTION_VARIANTS:\n",
    "        if fuzz.partial_ratio(line, q) >= threshold:\n",
    "            return True\n",
    "\n",
    "    for theme in ALL_THEMES:\n",
    "        if fuzz.partial_ratio(line, theme.lower()) >= threshold:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# ==========================\n",
    "# 5️⃣ SMART FIND_RESPONSE FUNCTION\n",
    "# ==========================\n",
    "def find_response(all_text, variants, threshold=70):\n",
    "    best_score = 0\n",
    "    best_index = -1\n",
    "\n",
    "    # Find best match line\n",
    "    for variant in variants:\n",
    "        for i, line in enumerate(all_text):\n",
    "            score = fuzz.partial_ratio(variant.lower(), line.lower())\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_index = i\n",
    "\n",
    "    if best_score < threshold or best_index == -1:\n",
    "        return \"\"\n",
    "\n",
    "    response_lines = []\n",
    "\n",
    "    # Include tail of matched line (e.g., same-line response)\n",
    "    matched_line = all_text[best_index].strip()\n",
    "    for variant in variants:\n",
    "        if variant.lower() in matched_line.lower():\n",
    "            split_pos = matched_line.lower().find(variant.lower()) + len(variant)\n",
    "            tail = matched_line[split_pos:].strip()\n",
    "            if tail and not is_question_or_theme(tail):\n",
    "                response_lines.append(tail)\n",
    "            break\n",
    "\n",
    "    # Collect all following lines until next question/theme\n",
    "    for j in range(best_index + 1, len(all_text)):\n",
    "        line = all_text[j].strip()\n",
    "        if is_question_or_theme(line):\n",
    "            break\n",
    "        response_lines.append(line)\n",
    "\n",
    "    full_response = \" \".join(response_lines).strip()\n",
    "    sentences = sent_tokenize(full_response)\n",
    "    valid_sentences = [s for s in sentences if not is_question_or_theme(s)]\n",
    "\n",
    "    return \" \".join(valid_sentences).strip()\n",
    "\n",
    "# ==========================\n",
    "# 6️⃣ PROCESS SINGLE DOCX FILE\n",
    "# ==========================\n",
    "def process_docx(filepath):\n",
    "    doc = Document(filepath)\n",
    "    lines = []\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        lines.append(clean_text(para.text))\n",
    "\n",
    "    for table in doc.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                lines.append(clean_text(cell.text))\n",
    "\n",
    "    results = []\n",
    "    for theme, question_dict in QUESTION_MAPPING.items():\n",
    "        for canonical, variants in question_dict.items():\n",
    "            answer = find_response(lines, variants)\n",
    "            results.append({\n",
    "                \"Theme\": theme,\n",
    "                \"Question\": canonical,\n",
    "                \"Response\": answer\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# ==========================\n",
    "# 7️⃣ PROCESS ALL DOCX FILES\n",
    "# ==========================\n",
    "for filename in os.listdir(INPUT_DIR):\n",
    "    if not filename.endswith(\".docx\"):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(INPUT_DIR, filename)\n",
    "    print(f\"Processing: {filename}\")\n",
    "    data = process_docx(filepath)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    county = filename.split(\"_\")[0].strip()\n",
    "    output_name = f\"{county}_gendered_enterprise.xlsx\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, output_name)\n",
    "\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"✅ Done. Extracted Excel files are saved in:\", OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
